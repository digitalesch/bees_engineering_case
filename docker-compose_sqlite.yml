version: '3.8'

services:
  airflow-webserver:
    image: apache/airflow:2.10.5
    container_name: airflow_webserver
    # restart: always
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
      AIRFLOW__WEBSERVER__SECRET_KEY: teste1234
      DATA_PATH: /opt/airflow/data
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./data:/opt/airflow/data
      - ./db/airflow.db:/opt/airflow/airflow.db
      - ./db:/opt/airflow/db
      - ./entrypoint.sh:/entrypoint.sh
      - ./scripts/:/scripts
    ports:
      - "8080:8080"
    entrypoint: ["/bin/bash", "/entrypoint.sh"]

  airflow-scheduler:
    image: apache/airflow:2.10.5
    container_name: airflow_scheduler
    restart: always
    depends_on:
      - airflow-webserver
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: sqlite:////opt/airflow/airflow.db
      AIRFLOW__WEBSERVER__SECRET_KEY: teste1234
    volumes:
      - ./dags:/opt/airflow/dags
      - ./data:/opt/airflow/data
      - ./logs:/opt/airflow/logs
      - ./db:/opt/airflow/db
      - ./db/airflow.db:/opt/airflow/airflow.db
      - ./scripts/:/scripts
    command: >
      bash -c "pip install -r /scripts/requirements.txt && airflow scheduler"